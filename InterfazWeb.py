import streamlit as st
import os
from pathlib import Path
import tempfile
from AgenteOpenEvidence import RAGSystem, RAGResponse
import time
from dotenv import load_dotenv

load_dotenv()

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="RAG System - OpenEvidence",
    page_icon="üîç",
    layout="wide"
)

@st.cache_resource
def initialize_rag_system():
    """Inicializa el sistema RAG con Azure OpenAI"""
    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION")

    if not all([api_key, endpoint, deployment, api_version]):
        st.error("‚ö†Ô∏è Faltan variables de entorno para Azure OpenAI")
        st.stop()

    return RAGSystem(
        openai_api_key=api_key,
        openai_endpoint=endpoint,
        deployment_name=deployment,
        api_version=api_version,
        model_name=deployment,
        storage_path="streamlit_knowledge_base"
    )

# Funci√≥n para mostrar estad√≠sticas
def show_stats(rag_system):
    """Muestra estad√≠sticas del sistema"""
    stats = rag_system.get_system_stats()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìö Documentos", stats.get('total_documents', 0))
    
    with col2:
        st.metric("üìÑ Chunks", stats.get('total_chunks', 0))
    
    with col3:
        st.metric("üß† Modelo LLM", stats.get('llm_model', 'N/A'))
    
    with col4:
        st.metric("üî§ Embeddings", stats.get('embedding_model', 'N/A'))

# Funci√≥n para mostrar documentos
def show_documents(rag_system):
    """Muestra lista de documentos"""
    docs = rag_system.list_documents()
    
    if not docs:
        st.info("üì≠ No hay documentos en el sistema")
        return
    
    st.subheader("üìö Documentos en el sistema")
    
    for i, doc in enumerate(docs, 1):
        with st.expander(f"üìÑ {doc['source']} ({doc.get('tokens', 0)} tokens)"):
            st.write(f"**ID:** {doc.get('doc_id', 'N/A')}")
            st.write(f"**Procesado:** {doc.get('processed_at', 'N/A')}")
            st.write(f"**Tokens:** {doc.get('tokens', 0)}")
            if 'extracted_date' in doc:
                st.write(f"**Fecha extra√≠da:** {doc['extracted_date']}")

# Funci√≥n para mostrar respuesta RAG
def show_rag_response(response: RAGResponse):
    """Muestra la respuesta del sistema RAG"""
    # Respuesta principal
    st.markdown("### ü§ñ Respuesta")
    st.write(response.answer)
    
    # Barra de confianza
    st.markdown("### üìä Confianza")
    confidence_color = "green" if response.confidence > 0.7 else "orange" if response.confidence > 0.4 else "red"
    st.progress(response.confidence, text=f"Confianza: {response.confidence:.2f}")
    
    # Fuentes utilizadas
    if response.sources:
        st.markdown("### üìñ Fuentes utilizadas")
        
        for i, source in enumerate(response.sources, 1):
            with st.expander(f"üìÑ Fuente {i}: {source['source']} (Score: {source['score']:.3f})"):
                st.write(source['text'])
                st.caption(f"Chunk {source.get('chunk_index', 'N/A')} - ID: {source.get('doc_id', 'N/A')}")

# Funci√≥n principal
def main():
    st.title("üîç Sistema RAG - OpenEvidence Clone")
    st.markdown("---")
    
    # Inicializar sistema RAG
    rag_system = initialize_rag_system()
    
    # Sidebar para configuraci√≥n
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n")
        
        # Mostrar estad√≠sticas
        show_stats(rag_system)
        
        st.markdown("---")
        
        # Secci√≥n de carga de documentos
        st.header("üìÅ Cargar Documentos")
        
        # Upload de archivos
        uploaded_files = st.file_uploader(
            "Selecciona archivos",
            accept_multiple_files=True,
            type=['pdf', 'docx', 'txt', 'md'],
            key="file_uploader"
        )
        
        if uploaded_files:
            for uploaded_file in uploaded_files:
                # Crear una clave √∫nica para cada bot√≥n
                button_key = f"process_{uploaded_file.name}_{uploaded_file.size}"
                
                if st.button(f"üì§ Procesar {uploaded_file.name}", key=button_key):
                    with st.spinner(f"Procesando {uploaded_file.name}..."):
                        try:
                            # Guardar archivo temporalmente
                            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                                tmp_file.write(uploaded_file.getvalue())
                                tmp_path = tmp_file.name
                            
                            # Procesar archivo
                            success = rag_system.add_document(tmp_path)
                            
                            # Limpiar archivo temporal
                            os.unlink(tmp_path)
                            
                            if success:
                                st.success(f"‚úÖ {uploaded_file.name} procesado exitosamente")
                                time.sleep(1)  # Peque√±a pausa para mostrar el mensaje
                                st.rerun()  # Reemplaza st.experimental_rerun()
                            else:
                                st.error(f"‚ùå Error procesando {uploaded_file.name}")
                        except Exception as e:
                            st.error(f"‚ùå Error procesando {uploaded_file.name}: {str(e)}")
        
        st.markdown("---")
        
        # A√±adir contenido web
        st.header("üåê Contenido Web")
        url_input = st.text_input("URL a procesar", key="url_input")
        
        if st.button("üåê Procesar URL", key="process_url_btn") and url_input:
            with st.spinner(f"Procesando {url_input}..."):
                try:
                    success = rag_system.add_web_content(url_input)
                    
                    if success:
                        st.success(f"‚úÖ URL procesada exitosamente")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error(f"‚ùå Error procesando URL")
                except Exception as e:
                    st.error(f"‚ùå Error procesando URL: {str(e)}")
        
        st.markdown("---")
        
        # A√±adir texto manual
        st.header("‚úçÔ∏è Texto Manual")
        text_input = st.text_area("Texto a a√±adir", height=100, key="text_input")
        source_name = st.text_input("Nombre de la fuente", value="texto_manual", key="source_name")
        
        if st.button("‚ûï A√±adir Texto", key="add_text_btn") and text_input:
            with st.spinner("Procesando texto..."):
                try:
                    success = rag_system.add_text(text_input, source_name)
                    
                    if success:
                        st.success("‚úÖ Texto a√±adido exitosamente")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("‚ùå Error a√±adiendo texto")
                except Exception as e:
                    st.error(f"‚ùå Error a√±adiendo texto: {str(e)}")
    
    # √Årea principal
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üí¨ Chat con tus documentos")
        
        # Inicializar historial de chat
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # Mostrar historial de chat
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                if message["role"] == "assistant" and "response" in message:
                    show_rag_response(message["response"])
                else:
                    st.write(message["content"])
        
        # Input de chat
        if prompt := st.chat_input("Haz una pregunta sobre tus documentos..."):
            # A√±adir mensaje del usuario
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with st.chat_message("user"):
                st.write(prompt)
            
            # Generar respuesta
            with st.chat_message("assistant"):
                with st.spinner("Buscando en documentos..."):
                    try:
                        response = rag_system.ask(prompt)
                        
                        show_rag_response(response)
                        
                        # Guardar respuesta en historial
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": response.answer,
                            "response": response
                        })
                    except Exception as e:
                        st.error(f"‚ùå Error generando respuesta: {str(e)}")
    
    with col2:
        st.header("üìö Documentos")
        
        # Bot√≥n para limpiar historial
        if st.button("üóëÔ∏è Limpiar Chat", key="clear_chat_btn"):
            st.session_state.messages = []
            st.rerun()  # Reemplaza st.experimental_rerun()
        
        # Mostrar documentos
        show_documents(rag_system)

if __name__ == "__main__":
    main()